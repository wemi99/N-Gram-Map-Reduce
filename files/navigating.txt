Navigating in the Storm: Using Astrolabe to Adaptively Configure
Web Services and Their Clients
Kenneth P. Birman, Robbert van Renesse and Werner Vogels1
Dept. of Computer Science, Cornell University
{ken,rvr,vogels}@cs.cornell.edu
Abstract
The dramatic growth of distributed computing
applications is creating both an opportunity and a
daunting challenge for users seeking to build
applications that will play critical roles in their
organization. Here, we discuss the use of a new
system, Astrolabe, to automate self-configuration,
monitoring, and to control adaptation. Astrolabe
operates by creating a virtual system-wide
hierarchical database, which evolves as the underlying
information changes. Astrolabe is secure, robust
under a wide range of failure and attack scenarios,
and imposes low loads even under stress. To focus the
discussion, we structure it around a hypothetical Web
Services scenario. One of the major opportunities
created by Astrolabe is to allow Web Services client
systems to autonomically adapt when a data center
becomes slow or unreachable.
Keywords: Autonomic computing, Web Services, selfconfiguration,
distributed
monitoring,
system
management, adaptation.

1

Introduction

In this paper, we describe an information
management service called Astrolabe, and its use in
building new styles of “autonomic” computing
applications. Our central premise is that large-scale
distributed systems, such as data centers hosting Web
Service applications and client computers accessing
them over the network, are far too fragile today. We
see this fragility as a direct consequence of inadequate
systems support. New tools to assist such applications
in self-configuration, monitoring and adaptation will
promote advances in application robustness and ease of
use. Although the discussion focuses on Web Services,

1

we believe that Astrolabe will also find application in a
number of other kinds of systems.
Astrolabe is aimed at two classes of “users”. The
first is a human administrator of a complex system – an
individual typical of the usual target audience for
monitoring technologies. But Astrolabe also treats the
application itself as a kind of “user.” By treating
Astrolabe as an integral part of the application,
developers can build systems that automatically react to
stresses that traditionally required human operator
intervention. That is, Astrolabe can be an enabler for a
new kind of autonomic behavior.
Astrolabe works by monitoring the dynamically
changing state of a collection of distributed resources,
reporting high quality “local” data and summaries of
remote information collected system-wide to its users. It
organizes this data into a hierarchy of domains, which
we call zones, and structures each zone as a small
relational database – a table, with a row for each
underlying zone or system component, and a column
for each of a set of monitored attributes. Attributes may
be redefined while the system is running, and updates
propagate within seconds, even in huge networks. A
novel peer-to-peer protocol is used to implement the
Astrolabe system, which operates without any central
servers.
Much of the power of Astrolabe stems from its
ability to support online data mining and data fusion.
The system continuously computes summaries of the
raw data it monitors, using on-the-fly aggregation. The
aggregation mechanism is controlled by SQL queries,
and operates by extracting summaries of data from each
zone, then assembling these into higher-level database
relations. By reprogramming these features on the fly
(a task very much like asking a database to compute a
dynamically materialized relation), a human user can
reconfigure Astrolabe within seconds, causing the

The authors were supported by DARPA/AFRL grant RADC F30602-99-1-0532, by AFOSR/MURI grant F4962002-1-0233, Microsoft Research BARC and the Cornell/AFRL Information Assurance Institute.

system to begin tracking information that it may not
even have been instrumenting before the request. Thus,
as the needs of its users change, the behavior of the
system can adapt to respond to those new requirements.
(Aggregation can also be valuable even if the “user” is
actually the application itself, but in this case the
aggregation queries would be predefined ones and
wouldn’t change while the system is running). The
speed and agility of the technology open the door to a
completely new way of viewing the system monitoring
and control task.
Astrolabe’s aggregation mechanisms are analogous
to database queries. When the underlying information
changes, Astrolabe will automatically and rapidly
recompute the associated aggregates and report the
changes to applications that have registered their
interest. Even in huge networks, any change is soon
visible everywhere. For example, suppose that a few
servers in a data center come under a distributed denial
of service attack. Suspecting this, an administrator
might ask Astrolabe to capture some sort of statistic
symptomatic of attack – perhaps, the rate of incomplete
attempted connections to each server. In doing so,
Astrolabe might also be asked to begin collecting
instrumentation of a type that it had not previously been
monitoring.
Astrolabe has potential access to a great variety of
host-maintained statistics and can also tap into data
maintained by the application or even stored in files
and databases. Thus, subject to user-enforced
permissions, a wealth of information is potentially
available to the individual operating the system, as well
as to application programs that exploit Astrolabe as a
standard infrastructure for capturing system status data.
We see Astrolabe as a new kind of system-wide service
that, if deployed widely enough, could encourage a new
generation of applications that adapt under stress more
rapidly and more automatically than is possible in the
absence of such services. The value of Astrolabe in
such a setting is multiple: It brings standards to the
monitoring task, so that all aspects of an application
fall under a single umbrella. It offers a form of “onestop-shopping”, bringing standardization to the way
that monitored data is delivered to users, both human
and programs. And it offers robustness and security,
which are often lacking when such problems are
tackled in ad-hoc ways.
More specifically, the Astrolabe data monitoring
protocol is extremely robust. Even if the applications it
instruments are under heavy load, and even if the

network is seriously degraded, within a short period all
servers in the data center and perhaps even all clients of
the system will see the situation. Healthy nodes can
then respond in a coordinated way, for example by
shifting work away from the affected servers and
towards backup servers running in a different data
center. The ultimate value of Astrolabe is that even
when everything else is malfunctioning, there is a good
chance that Astrolabe will remain operational.
We are not aware of any prior system offering the
mixture of scalability, robustness and security seen in
Astrolabe. These properties will be crucial in
tomorrow’s large, extremely critical computing
applications, because the need for autonomic tools is
most acute in large-scale applications that demand high
availability even during disruption or distributed denial
of service attacks. In traditional, centralized,
implementations of system monitoring and control
functionality, these issues can emerge as impediments
to the user. For example, if computers are tracking
state that changes once every second, and we have
10,000 such computers, the centralized database would
be expected to keep up with 10,000 updates per second,
a massive load. Even if such a system could be
implemented, which is doubtful, during periods when
that central system becomes unavailable, the autonomic
capabilities would be disabled. Yet such a disruption is
unlikely to impact Astrolabe, hence it can guide the
application towards a viable self-repair strategy.
This paper starts with a brief discussion of our
vision of how autonomic computing might be
accomplished using tools like Astrolabe. Next, we
provide a technology review focused on the data mining
features of Astrolabe, which are based on its
aggregation mechanisms. Astrolabe gains scalability
and robustness at the price of generality, and we spend
some time looking at the limitations of the system and
their implications for developers and users.
In
particular, while Astrolabe is a database, it doesn’t
allow the user to do arbitrary database-style
transactions, and it is important to understand the
reasons and the degree to which one can work around
these limits. For reasons of brevity, this paper omits a
detailed scalability analysis, but we do summarize prior
work on this problem. Throughout, the paper uses a
Web Services scenario as its primary example. Indeed,
we believe that Astrolabe (and other similar
technologies) represent the best hope for making such
systems more autonomic.

2

Autonomic Computing

The phrase “autonomic computing” has different
meanings in the eyes of different kinds of users. Some
imagine a new era of self-aggregating computing
systems: a PDA, for example, that can automatically
discover input and display devices in each room the
user enters and dynamically configure a kind of virtual
PC on-the-fly. There has been much talk about a new
generation of wireless embedded sensors that might use
autonomic capabilities to self-configure, for example
after being scattered over a battlefield or a forest fire.
At the other end of the spectrum, some imagine data
centers with the kinds of serviceability and
management features common on RAID file servers.
And still others evoke the image of a completely selfmanaged distributed system in which parameter setting
and configuration is automated, problem diagnosis and
repair are commonplace and standardized, and hence
the total cost of ownership is dramatically reduced even
for ambitious configurations.
The scenario motivating much of our work emerges
from challenges of managing large data centers that are
part of 3-tier applications and, with the roll-out of Web
Services, may soon be integrated into a new kind of 4tier system.
Some analysts predict that trillions of
dollars of b2b commerce will be transacted over such
Web Services within the next decade. If so, we’ll need
a way to make these systems extremely robust, and the
match between Astrolabe and such a scenario seems
especially close.
To set the stage, let’s think about the evolving
business strategy of a typical online vendor. Most such
vendors have followed an evolutionary path that started
in the late 1990’s. Perhaps the vendor initially
operated a web site that users accessed through
browsers, with some of the content hosted off-site. Over
time, availability issues and a desire to customize such
a site will have resulted in a series of expansions, hence
the vendor now operates a substantial but “ad-hoc”
cluster containing not just its web servers, but also a
whole collection of database systems in support of
them, customer profiling applications that generate
customized content quickly on demand, transactional
order processing systems, fulfillment and billing
systems, and so forth. Very likely, the company is also
using some sort of message queuing or publishsubscribe technology to glue all of this together.
With the emergence of Web Services, a new and
very appealing business opportunity is arising. By

negotiating with application vendors in various sectors,
the company can potentially embed little bits of its
functionality into third-party applications.
For
example, a medical application might send its refill
orders directly through the vendor’s Web Services
system, tapping into the order fulfillment subsystems to
track status of the order and even to arrange third-party
billing to insurance companies.
The third-party
developer gets extra functionality and avoids needing to
implement a whole Web-based sales system (and
probably also gets a cut of the revenue stream). The
vendor sees in this the opportunity for an expansion of
its reach.
However, to operate this architecture, the vendor
needs a system with different properties than the one it
is based upon. What had been a business-to-consumer
relationship will now need to evolve into a direct
computer-to-computer interaction. In effect, a new tier
has been added to the existing 3-tier architecture,
consisting of thousands of “serverlets” deployed on
end-user systems, which function by interacting with
the vendors systems. If anything breaks in this new 4tier structure, the impact will be very widespread.
A great number of companies are pursuing a path
along the lines just described. The evolution of the
Web has pushed them down a path towards an
increasingly complex internal architecture, and towards
an increasingly “mission critical” role on behalf of the
application developers who will connect to the
corporate system over the Web.
They represent a
potential market for autonomic computing technology.
With that in mind, let’s consider the same
application from a more technical perspective, and
think about how the application will have evolved over
time, and what new requirements this creates.
We should first note that any company operating the
sort of complex data center just described was already
face some daunting administrative challenges even
without adding a 4th tier of automated client systems.
For example (and this is just one of dozens of
examples), we mentioned that publish-subscribe
architectures are very popular communication tools in
“loosely coupled” data centers. This popularity is
attributable to the way that publish-subscribe favors
incremental deployment. Once such an architecture is
adopted, one can expand it easily. To deploy a new
publisher or subscriber one need merely adhere to the
company’s proprietary data format standards and rules
for tagging messages with subject information.

On the other hand, publish-subscribe systems don’t
know anything about application semantics. This
means that if application A publishes a message that
really needs to be processed by application B, and B
happens to be down at that moment, the message bus
won’t detect a problem and A will simply be left
waiting, with no indication that B never picked up the
message. In effect, a publish-subscribe architecture
favors incremental deployment of new applications, but
lacks an explicit representation for a type of
dependency relationship common in RPC-based
systems. When an RPC would have thrown an
exception, triggering some sort of compensating action
in the application, a publish-subscribe system will fail
silently. (RPC, on the other hand, is poorly matched to
incremental deployments of the sort we’ve outlined).
More broadly, loosely coupled applications have
become widespread, yet often hold together only when
things are working properly.
When something
abnormal occurs, human intervention is almost always
needed, first to make sense of the disruption, then to
repair it, and then to restart processing. Our Web
vendor employs a small army of experts for this
purpose, and they are busy people.
The first observation, then, is that even before we
talk about Web Services, we’re looking at a problem
that begs for Autonomic Tools. Anything that could
help the system set parameters on its own, detect and
diagnose problems automatically, initiate self-repair,
reconfigure to better handle overload – would be
welcome.
But we lack ways of migrating this
functionality into applications. Human operators work
with all sorts of specialized tools, and bring specialized
insight into what the application actually does. Very
little of what they do can be automated. Needed is a
system-wide instrumentation infrastructure that
applications can tap into in as standardized and
incremental a manner as they tap into publish-subscribe
communication buses, and that would tackle the whole
question overlooked by publish-subscribe: representing
the large-scale system structure and state while it
operates, so that the application can compare the
current structure with the “correct” one and initiate
repairs when problems arise.
Now consider what the Web Services trends will do
to this 3-tier system. A Web Services system uses a
remote method call paradigm, yet the back-end
applications are often legacy programs operating in a
more batch-like style. In our scenario, the back-end
system is the entire hodge-podge of legacy applications

and message buses just described. As a result, with the
move to Web Services, a system that has worked
perfectly well for many years may suddenly seem
unexpectedly balky, may experience new kinds of
reliability or security problems, and may even be
perceived as a critical element in the path for important
business activities.
New styles of use will also mean that the legacy
system is confronted with much higher loads; often,
this compels a migration from a single machine to a
small cluster hosted within a corporate data center. As
the system grows to play a more and more vital role, it
will often seem advisable to break up that data center
into two or more centers, distributed geographically.
Thus, we take what had been a barely manageable data
center operation problem and turn it into a far more
complex problem that combines decentralization, new
metrics for “healthy behavior,” and a new style of fully
automated remote client.
Problems of system administration and control now
become particularly acute. Previously, when something
malfunctioned, the impact was visible to users working
behind browser interfaces – response time might be
poor, timeouts could occur, etc. Now, however, the
human user lives behind a new 4th tier of software, and
a problem within the vendor’s system can cause
applications running in hundreds of medical offices or
other remote settings to hang. The vendor’s system has
become a critical component in the eyes of both its
clients (the third party developers) and their clients (the
people working in the medical office). Not only has
our problem become harder, but it is also necessary to
do a much better job of solving it!
All of this leads to an enumeration of roles that
Autonomic Computing tools can play in automating the
current manual style of system management and
control. Starting at the core of the system, such tools
could be used in support of management of the server
cluster. For example, as we will see below, our
Astrolabe system can collect runtime statistics that
would rapidly reveal overloads, system outages, and
would make configuration data public in a standardized
format. Astrolabe isn’t the only way to obtain this
functionality, but however one implements it, any
autonomic system will require it.
Better monitoring functionality won’t eliminate the
role of the human operators, but does offer a way to
automate at least some functions that can’t currently be
automated for lack of a consistent way to obtain the

needed data. Of course, the underlying data will
change. Thus, whatever technology one selects, it is
important that it be able to capture rapidly changing
data, so that applications throughout the system can
react quickly as conditions evolve.
Notice how monitoring functionality of this sort can
offer a natural counterpart to a message bus or some
other “loosely coupled” communications tool. Earlier
we observed that the message bus doesn’t know that an
instance of application B should have been running. In
our scenario, A needs a response from B, and this
means that A needs a way to detect such problems
directly. Yet A and B may have been developed
independently and the developer of A may not be in any
position to ask B to export new interfaces or other
functionality. By deploying an agreed-upon monitoring
infrastructure, we arrive at a common standard into
which all components report their health, and that can
be used by all components to check on health. The
technology makes it easy for A to make sure that there
are some instances of B running.
Autonomic monitoring tools can also be useful in
the hands of a human administrator. The administrator
diagnosing a problem can easily and quickly
reconfigure the system to begin tracking a parameter
that might shed light on a problem, or to stop tracking
a parameter when a problem seems to have been
resolved. Especially important to the human user is
that the system be reconfigurable on the fly. This is
because many kinds of monitoring functionality have a
high cost impact on the running system. We wouldn’t
want that kind of monitoring to be enabled unless there
is a pressing reason to collect the data.

their clients. For example, client systems can publish
their experiences in communicating with one data
center or another. Suppose that A and B are serverlets
that issue requests to data center C. If machine A has a
problem connecting to C, by reporting that problem
through the infrastructure, A helps its neighbor, B,
avoid the same problem moments later. This kind of
edge-control over request routing is completely lacking
today. Yet it may be the only option for routing around
a major network disruption that is preventing requests
from A and B from reaching center C!
Again, this form of monitoring also offers new
power to human administrators. Traditionally, the
administrator of a Web Services system only “knows”
about client performance through what is observable at
the servers. With a client-side monitoring platform,
provided that the monitoring system is “more robust”
than the basic communication channels between the
clients and the servers, an administrator can potentially
monitor client response times and errors that the client
experiences. This would let the administrator see
problems that are not evident within the server cluster –
for example, network outages of the sort just described.
If a disruption occurs, rather than waiting for hundreds
of medical offices to call for technical support, the
administrative team may see the pattern long before it
becomes disruptive to client systems, and hence be in a
position to correct the problem or advise the client-side
serverlets to redirect their requests, so that a high
quality of end-user experience is maintained even
during periods of disruption.

All of the above observations apply within the core
system. As we consider the remote elements of a Web
Services configuration – our 4th tier – the power of a
standardized monitoring infrastructure becomes even
more evident. Traditionally, clients of a Web Services
system have almost no information available about the
state of the servers and very little help when problems
arise. For example, if a server is non-responsive, is this
a sign of a network problem or a server problem? What
would be the best fall-back option – should requests be
rerouted to the Tokyo data center, or merely sent to a
backup server in New York?

We’ve postulated some properties that may sound
almost magical – particularly this last one, in which the
monitoring infrastructure shared among the clients of a
system is visible to the administrators even during
periods when those client systems can’t reach some of
the data centers. More broadly, while there may be
dozens or even hundreds of machines in the data
center, there are probably tens of thousands of clients.
We’re postulating the ability to monitor the
dynamically changing states of tens of thousands of
machines, sharing that state and letting the machines at
the edges exploit it in automated ways, and somehow
having that state “reach” data centers that are not
directly reachable by the clients issuing Web Services
requests. How can all of this be done?

With a scalable monitoring infrastructure, we
introduce a channel through which the clients (the
serverlets) can share information among themselves,
and one allowing servers to share information with

In what follows, we’ll look more closely at how
Astrolabe can be used to accomplish these and similar
goals. The unique property of Astrolabe is not so much
that it can monitor a system in a flexible manner, but

rather that it actually has the properties just
enumerated. Under conditions when all else is failing,
Astrolabe will often continue to operate correctly, using
“peer to peer” communication patterns to route critical
information around the edges of a disruption. We see
this as one reason that Astrolabe could bring unique
value to autonomic settings.

3

The Astrolabe System

Astrolabe is best understood as a relational database
built using a peer-to-peer protocol2 running between
the applications or computers on which Astrolabe is
installed.
Like any relational database, the
fundamental building block employed by Astrolabe is a
tuple (a row of data items) into which values can be
stored. For simplicity in this paper, we’ll focus on the
case where each tuple contains information associated
with some computer. The technology is quite general,
however, and can be configured with a tuple per
application, or even with a tuple for each instance of
some type of file or database.
The data stored into Astrolabe can be drawn from
the management information base (MIB) of a computer,
extracted directly from a file, database, spreadsheet,
registry, or fetched from a user-supplied method
associated with some application program. Astrolabe
obtains flexibility by exploiting a recent set of standards
(ODBC, JDBC) whereby a system like ours can treat
the objects on a computer much like databases. Of
course, these capabilities are controlled by the security
policy of the computers to which Astrolabe is
connected, and in what follows, the reader should keep
in mind that only information Astrolabe has been
explicitly permitted to access are available within the
system. Moreover, the ability to write data into
Astrolabe doesn’t necessarily imply that the same
system can read data out of Astrolabe. Thus, one can
report “sensitive” data with some assurance that only
appropriately authorized access will be possible.
Astrolabe is flexible about data types, supporting the
usual basic types but also allowing the application to
supply arbitrary information encoded with XML. The
2

The term « peer-to-peer » is often used in conjunction
with scalable file systems for sharing media content.
Here, we refer only to the communication pattern seen
in such systems, which involves direct pairwise
communication between « client » computers, in
contrast to a more traditional star-like client-server
architecture where all data passes through the
centralized servers.

Name

Load

Weblogic?

SMTP?

Version

Name
Load
Weblogic?
SMTP? Version
swift
2.0
0
1
6.2
falcon
1.5
1SMTP? Version
0
4.1
Name
Load
Weblogic?
swift
2.0
0
1
6.2
cardinal
4.5
1
0
6.0
falcon
1.5
1
0
4.1
swift
2.0
0
1
6.2
cardinal
4.5
1
0
6.0
falcon
1.5
1
0
4.1
cardinal
4.5
1
0
6.0

Figure 1: Three Astolabe domains
only requirement is that the total size of the tuple be no
more than a few k-bytes; much larger objects can be by
identified by a URL or other reference, but the data
would not be replicated in Astrolabe itself.
The specific data pulled into Astrolabe is specified
in a configuration certificate. Should needs change,
and subject to the security restrictions just mentioned
(discussed further in Section 3) the configuration
certificate can be modified and, within a few seconds,
Astrolabe will reconfigure itself accordingly.
Astrolabe groups small sets of tuples into relational
tables. Each such table consists of perhaps 30 to 60
tuples containing data from sources physically or
logically close to one-another in the network. This
grouping (a database administrator would recognize it
as a form of schema) can often be created
automatically, using latency and network addresses to
identify nearby machines.
However, the system
administrator can also specify a desired layout
explicitly.
For example, in the setting discussed
previously, machines A and B were probably in the
same region.
They are likely to have similar
experiences when communicating to the data center,
and this is why they can benefit by sharing that data
with one-another so that B can “learn” from A’s
problems.
Where firewalls are present, Astrolabe employs a
standard tunneling method to send messages to
machines residing behind the firewall and hence not
directly addressable.
This approach also allows
Astrolabe to deal with network address translation
(NAT) filters.
The data collected by Astrolabe evolves as the
underlying information sources report updates, hence
the system constructs a continuously changing database
using information that actually resides on the
participating computers. Figure 1 illustrates this: we
see a collection of small database relations, each tuple

corresponding to one machine, and each relation
collecting tuples associated with some set of nearby
machines. In this figure, the data stored within the
tuple includes the name of the machine, its current
load, an indication of whether or not various servers are
running on it, and the “version” for some application.
Keep in mind that this selection of data is completely
determined by the configuration certificate.
In
principle, any data available on the machine or in any
application running on the machine can be exported.
In particular, spreadsheets and databases can easily be
configured to export data to Astrolabe.
The same interfaces that enable us to fetch data so
easily also make it easy for applications to use
Astrolabe, if they have permission to do so. Most
commonly, an application would access the Astrolabe
relations just as it might access any other table,
database or spreadsheet.
As updates occur, the
application receives a form of event notifying it that the
table should be rescanned. Thus, with little or no
specialized programming, data from Astrolabe data
could be « dragged » into a local database, spreadsheet,
or even onto a web page. As the data changes, the
associated application will receive refresh events.
Astrolabe is intended for use in very large networks,
hence this form of direct access to local data cannot be
used for the full dataset: while the system does capture
data throughout the network, the amount of information
would be unwieldy and the frequency of updates
excessive.
Accordingly, although Astrolabe does
provide an interface whereby a remote region’s data
can be accessed, the normal way of monitoring remote
data is through aggregation queries.
An aggregation query is, as the name suggests, just
an SQL query that operates on these leaf relations,
extracting a single summary tuple from each that
reflects the globally significant information within the
region. Sets of summary tuples are concatenated by
Astrolabe to form summary relations (again, the size is
typically 30 to 60 tuples each), and if the size of the
system is large enough so that there will be several
summary relations, this process is repeated at the next
level up, and so forth. Astrolabe is thus a hierarchical
relational database. Each of the summaries is updated,
in real-time, as the leaf data from which it was formed
changes. Even in networks with thousands or millions

of computers, updates are visible system-wide within a
few tens of seconds (Figure 2).
A computer using Astrolabe will, in general, keep a
local copy of the data for its own region and
aggregation (summary) data for each region above it on
the path to the root of this hierarchy.
As just
explained, the system maintains the abstraction of a
hierarchical relational database. Physically, however,
this hierarchy is an illusion, constructed using a peerto-peer protocol, somewhat like a jig-saw puzzle in
which each computer has ownership of one piece and
read-only replicas of a few others. Our protocols
permit the system to assemble the puzzle as a whole
when needed. Thus, while the user thinks of Astrolabe
as a somewhat constrained but rather general database,
accessed using conventional programmer APIs and
development tools, this abstraction is actually an
illusion, created on the fly.
The peer-to-peer protocol used for this purpose is, to
first approximation, easily described (see reference [7]
for details). Each Astrolabe system keeps track of the
other machines in its zone, and of a subset of contact
machines in other zones. This subset is selected in a
pseudo-random manner from the full membership of
the system (again, a peer-to-peer mechanism is used to
track approximate membership; for simplicity of
exposition we omit any details here). At some fixed
frequency, typically every 2 to 5 seconds, each
participating machine sends a concise state description
to a randomly selected destination within this set of
neighbors and remote contacts. The state description is
very compact and lists versions of objects available
from the sender. We call such a message a « gossip »
event. Unless an object is very small, the gossip event
will not contain the data associated with it.
Upon receiving such a gossip message, an Astrolabe
system can identify information which may be stale at
the sender’s machine (it will notice that timestamps are
out of date) or that may be more current at the sender
than on its own system. We say may because time
elapses while messages traverse the network, hence no
machine actually has current information about any
other. Our protocols are purely asynchronous: when
sending a message, the sender does not pause to wait
for it to be received. Indeed, the protocol makes no
effort to ensure that gossip gets to its destinations.

If a receiver of a gossip message discovers that it has
data missing at the sender machine, a copy of that data
is sent back to the sender. We call this a push event.
Conversely, if the sender has data lacking at the
receiver, a pull event occurs: a message is sent
requesting a copy of the data in question. Again, these
actions are entirely asynchronous; the idea is that they
will usually be successful, but if not (e.g. if a message is
Dynamically changing
query output is visible
Avg
system-wide Name Load
SF
NJ
Paris

Name
swift
falcon
cardinal

Load
2.0
1.5
4.5

Weblogic?
0
1
1

SMTP?
1
0
0

2.6
1.8
3.1

Word
Version
6.2
4.1
6.0

San Francisco

WL contact
123.45.61.3
127.16.77.6
14.66.71.8

SMTP contact
123.45.61.17
127.16.77.11
14.66.71.12

…

Name
gazelle
zebra
gnu

Load
1.7
3.2
.5

SQL query
“summarizes”
data
Weblogic?
0
0
1

SMTP?
0
1
0

Word
Version
4.5
6.2
6.2

…

New Jersey

Figure 2: Hierarchy formed when data-mining with an
aggregation query fuses data from many sources.
lost in the network, received very late, or if some other
kind of failure occurs), the same information will
probably be obtained from some other source later.
One can see that through exchanges of gossip
messages and data, information should propagate
within a network over an exponentially increasing
number of randomly selected paths among the
participants. That is, if a machine updates its own row,
after one round of gossip, the update will probably be
found at two machines. After two rounds, the update
will probably be at four machines, etc. In general,
updates propagate in log of the system size – seconds or
tens of seconds in our implementation. In practice, we
configure Astrolabe to gossip rapidly within each zone
(to take advantage of the presumably low latency) and
less frequently between zones (to avoid overloading
bottlenecks such as firewalls or shared network links).
The effect of these steps is to ensure that the
communication load on each machine using Astrolabe
and also each communication link involved is bounded
and independent of network size.
Recall that we talked about a scenario in which a
problem prevents clients A and B from talking to data
center C, and yet suggested that Astrolabe might
manage to report that problem to a human
administrator or a server running at that same data
center. At the time, perhaps this sounded like magic.
But the gossip pattern just described has every chance
of doing just that! Even though communication from A

to C is disrupted, there is no reason to suspect that the
data path from A to some totally different place, D, is
affected, and perhaps the path from D to C is working.
Gossip can thus route data along very indirect paths.
Moreover, since Astrolabe is shipping relatively small
amounts of information, it can potentially remain
healthy under circumstances where larger requests
might not get through in a timely manner. And since
Astrolabe makes no effort at all to “wait” for its
messages to get through, if a disruption occurs, but then
eases up, the data that finally penetrates to the data
center is likely to be fresh information reporting the
current state of the system, not very old status data that
is finally getting through after a very long delay. What
may have seemed like magic is thus revealed to be a
symptom of excess: Astrolabe sends information along
so many possible paths, and is so patient about probing
all possible paths, that if there is a way to route
information to its destinations, that information will get
through – and probably, will do so rather quickly!
We’ve said that Astrolabe gossips about objects. In
our work, a tuple is an object, but because of the
hierarchy used by Astrolabe, a tuple would only be of
interest to a receiver in the same region as the sender.
In general, Astrolabe gossips about information of
shared interest to the sender and receiver. This could
include tuples in the regional database, but also
aggregation results for aggregation zones that are
ancestors of both the sender and receiver. Thus, even
when the network between the data center C and the
clients A and B is disrupted, a human administrator at
C can potentially reconfigure the instrumentation at A
and B – and see the effect within seconds. Astrolabe
will remain healthy even during periods of intense
turmoil.
After a round of gossip or an update to its own tuple,
Astrolabe recomputes any aggregation queries affected
by the update. It then informs any local readers of the
Astrolabe objects in question that their values have
changed, and the associated application rereads the
object and refreshes its state accordingly. Thus,
aggregates propagate much as do leaf updates, except
that aggregates do so on a wide-area scale while leaf
updates are visible only within the zone where the leaf
node resides.
ODBC and JDBC are very flexible in their support
for “drag and drop” applications. Thus, Astrolabe can
easily be integrated with other kinds of systems. For
example, if an Astrolabe aggregation output is pulled
from Astrolabe into a web page, that web page can be

set up to update itself automatically each time the
Astrolabe data changes. The change would be expected
to reach the server within a delay logarithmic in the
size of the network, and proportional to the gossip rate.
Using a 2-second gossip rate, an update would reach all
members in a system of 10,000 computers in roughly
25 seconds. Of course, the gossip rate can be tuned to
make the system run faster, or slower, depending on the
importance of rapid responses and the available
bandwidth.
Our description oversimplifies. Astrolabe actually
supports multiple aggregation queries, each creating its
own hierarchy. And one can run multiple instances of
the entire system, each supporting some separate goal –
perhaps, one Astrolabe to monitor the data center and
servers, and a separate one to monitor the states of
clients.
The system can also be configured to
accommodate heterogeneity of the leaf nodes, whereas
we have presented it as if each leaf node has identical
information.
Moreover, the same peer-to-peer
mechanisms used to propagate updates are also used to
propagate new configuration certificates and new
aggregation queries, hence the behavior of the system
can be modified on the fly, as needs change. Details on
these aspects, together with an enlarged discussion of
our peer-to-peer protocol can be found in [7].

4

Consistency, Security and Expressiveness

The power of the Astrolabe data mining mechanisms
is limited by the physical layout of the Astrolabe
database and by our need, as builders of the system, to
provide a solution that is secure and scalable. This
section discusses some of the implications of these
limitations for the Astrolabe user.

4.1

Consistency

Although Astrolabe is best understood as a form of
hierarchical database, the system doesn’t support
transactions, the normal consistency model employed
by databases. A transaction is a set of database
operations (database read and update actions) that are
performed in accordance with what are called ACID
properties. The consistency model, serializability,
embodies the guarantee that a database will reflect the
outcome of committed transactions, and will be in a
state that could have been reached by executing those
transactions sequentially in some order.
In contrast, Astrolabe is accessible by read-only
operations on the local zone and aggregation zones on
the path to the root. Update operations can only be

performed by a machine on the data stored in its own
tuple.
If Astrolabe is imagined as a kind of replicated
database, a further distinction arises. In a replicated
database each update will be reflected at each replica.
Astrolabe offers a weaker guarantee: if a participating
computer updates its tuple and then leaves the tuple
unchanged for a sufficiently long period of time, there
is a very high probability that the update will become
visible to all non-faulty computers. Indeed, this
probability converges to 1.0 in the absence of network
partitioning failures. However, if updates are more
frequent, a “new” value could overwrite an “older”
value, so that some machines might see the new update
but miss the prior one.
Astrolabe gains a great deal by accepting this
weaker probabilistic consistency property: the system is
able to scale with constant loads on computers and
links, and is not forced to stop and wait if some
machine fails to receive an update. In contrast, there is
a well-known impossibility result that implies that a
database system using the serializability model may
need to pause and wait for updates to reach
participating nodes. Indeed, a single inopportune
failure can prevent a replicated database from making
progress. Jointly, these results limit the performance
and availability of a replicated database. Astrolabe,
then, offers a weaker consistency property but gains
availability and very stable, predictable performance by
so doing.
Aggregation raises a different kind of consistency
issue. Suppose that an aggregation query reports some
property of a zone, such as the least loaded machine,
the average humidity in a region, etc. Recall that
aggregates are recomputed each time the Astrolabe
gossip protocol runs. One could imagine a situation in
which machine A and machine B concurrently update
their own states; perhaps, their loads change. Now
suppose that an aggregation query computes the
average load. A and B will both compute new
averages, but the values are in some sense unordered in
time: A’s value presumably reflects a stale version of
B’s load, and vice versa. Not only does this imply that
the average computed might not be the one expected, it
also points to a risk: Astrolabe (as described so far)
might report aggregates that bounce back and forth in
time, first reflecting A’s update (but lacking B’s more
current data), then changing to reflect B’s update but
“forgetting” A’s change. The fundamental problem is
that even if B has an aggregation result with a recent

timestamp, the aggregate could have been computed
from data which was, in part, more stale than was the
data used to compute the value it replaces.
To avoid this phenomenon, Astrolabe tracks
minimum and maximum timestamp information for the
inputs to each aggregation function. A new aggregate
value replaces an older one only if the minimum
timestamp for any input to that new result is at least as
large as the maximum timestamp for the one it
replaces. It can be seen that this will slow the
propagation of updates but will also ensure that
aggregates advance monotonically in time. Yet this
stronger consistency property also brings a curious sideeffect: if two different Astrolabe users write down the
series of aggregate results reported to them, those
sequences of values could advance very differently.
Perhaps, A sees its own update reflected first, then later
sees both its own and B’s; B might see its update first,
then later both, and some third site, C, could see the
system jump to a state in which both updates are
reflected. Time moves forward, but different users see
events in different order and may not even see the
identical events! This tradeoff seems to be fundamental
to our style of distributed data fusion.

4.2

Security Model and Mechanisms

A related set of issues surround the security of our
system.
Many peer-to-peer systems suffer from
insecurity and are easily incapacitated or attacked by
malfunctioning or malicious users.
Astrolabe is
intended to run on very large numbers of machines,
hence the system itself could represent a large-scale
security exposure.
To mitigate such concerns, we’ve taken several
steps. First, Astrolabe reads but does not write data on
the machines using it. Moreover, it can only read data
that some user previously configured the system to
make available to Astrolabe (for example, on a
Windows platform, if data is not reported through the
Internet Information Service, Astrolabe probably can’t
get to it). Thus, while Astrolabe can pull a great variety
of data into its hierarchy, the system doesn’t take the
converse action of reaching back onto the participating
machines and changing values within them, except to
the extent that applications explicitly read data from
Astrolabe. Moreover, both writing to Astrolabe and
reading from it involves presenting a valid certificate in
which the user is explicitly permitted to perform that
action. One can design an Astrolabe hierarchy in
which systems report “sensitive” data that they are

willing to share with administrators, but not with each
other, and the system is quite capable of enforcing this
(one does need to encrypt the data flowing between the
Astrolabe agents themselves, but virtual private
network (VPN) technology is adequate for this
purpose).
The issue thus becomes one of administrative policy
and trustworthiness: what data should be reported to
Astrolabe, how should it be aggregated, and can the
data stored in Astrolabe be trusted? In what follows,
we assume that Astrolabe instances are non-malicious,
but that the computers on which they run can fail, and
that software bugs (hopefully, rare) could corrupt
individual systems. To overcome such problems,
Astrolabe includes a public-key infrastructure (PKI)
that is built into the code. We employ digital
signatures to authenticate data. Although machine B
may learn of machine A’s updates through a third
party, unless A’s tuple is correctly signed by A’s private
key, B will reject it. Astrolabe also limits the
introduction of configuration certificates and
aggregation queries by requiring keys for the parent
zones within which these will have effect; by
controlling access to those keys, it is possible to prevent
unauthorized users from introducing expensive
computations or configuring Astrolabe to pull in data
from participating hosts without appropriate
permissions.
We believe that taken jointly, these mechanisms
offer the developer adequate power to express any
desired security policy.

4.3

Query Limitations

A final set of limitations arises from the lack of a
join feature in the aggregation query mechanism. As
seen above, Astrolabe performs data mining by
computing summaries of the data in each zone, then
gluing these together to create higher level zones on
which further summaries can be computed.
The
approach lacks a way to compute results for queries that
require cross-zone joins.
For example, suppose that Astrolabe were used to
detect distributed denial of service attacks provoking
the sort of data center disruption we discussed earlier.
One might want to express a data mining query along
the following lines: “detect servers under attack and,
for each such server, suggest to its clients the healthy
server best positioned to take over its workload.” When
C comes under attack, such a query might recommend
that A and B try D as a backup. The natural way to

express this as a query in a standard database would
involve a join. In Astrolabe, one would need to express
this as two aggregation queries, one to compute a
summary of apparent attacks and the other, using
output from the first as an input, tracking down the best
backup machines.
In general, this points to a
methodology for dealing with joins by “compiling”
them into multiple current aggregation queries.
However, at present, we have not developed this insight
into a general mechanism; users who wish to perform
joins would need to break them up in this manner, by
hand. Moreover, it can be seen that while this
approach allows a class of join queries to compile into
Astrolabe’s aggregation mechanism, not all joins can
be so treated: the method only works if the size of the
dataset needed from the first step of the join, and
indeed the size of the final output, will be sufficiently
small.
Configuring Astrolabe so that one query will use the
output of another as part of its input raises a further
question: given that these queries are typically
introduced into the system while it is running, how
does the user know when the result is “finished”? We
have a simple answer to this problem, based on a
scheme of counting the number of sub-zones reflected
in an aggregation result. The idea is that as a new
aggregate value is computed, a period passes during
which only some of the leaf zones have reported values.
At this stage the parent aggregation zone is not yet fully
populated with data. However, by comparing a count of
the number of reporting child zones with a separately
maintained count of the total number of children,
applications can be shielded from seeing the results of
an aggregation computation until the output is stable.
By generalizing this approach, we are also able to
handle failures or the introduction of new machines; in
both cases, the user is able to identify and disregard
outputs representing transitional states. The rapid
propagation time for updates ensures that such
transitional conditions last for no more than a few
seconds.

5

Example

For the purpose of illustrating the ideas behind the
system, however, we now drill down on some problems
that might arise in a hypothetical commercial web
service application. To avoid repeating the material
covered in Section 2, we’ll focus on a case in which an
administrator is trying to diagnose a severe disruption
within a data center that has been broken up into a
small number of geographically separate centers, each

containing a few dozen machines and hosting an even
larger number of applications.
We’ll assume that the problem initially becomes
visible not within the data center, but instead out near
the clients – serverlets running on machines A and B in
our previous scenario. For example, A may have issued
a request to a web service platform, which eventually
timed out. Notice that the problem may be a network
outage, sluggish response in the web services system
itself, a crash of that platform, an internal queuing
delay (many of these systems use message oriented
middleware such as MQSeries or MSMQ), bursty
behavior in old legacy software, or an inappropriately
set parameter. The server may even be under some
form of attack. Lacking a technology like Astrolabe,
we have few tools to assist in diagnosing such
problems: Modern computing systems operate in the
dark. A vast amount of information is potentially
relevant to their correct configuration and operation,
yet little of this information is ever represented or
available to the application. Indeed, in a modern Web
Services setting, even using state-of-the-art solutions,
the administrator would probably never even become
aware of A’s problems – until a human user dependent
on A, perhaps one of thousands of such end-users, picks
up the telephone and calls the service center!
With Astrolabe, we can easily instrument both the
many platforms that comprise the center, and the states
of the client systems. And the administrator, noticing a
sudden pattern of client delays (she’ll see this within
seconds after it occurs), could reconfigure this
instrumentation on the fly. Assuming that Astrolabe
was set up to do so, the instrumentation mechanism
taps into the full set of data items available on the
various data center servers: parameters in their MIBs
(such as paging and I/O rates, network statistics, etc),
application-specific parameters, information in
databases or files, etc. Thus the center’s administrator
can view all of this data as comprising a long “tuple”
with one field for each potential data item. She merely
selects items of interest within the set, and Astrolabe
will reach into the system and, given appropriate
permissions, extract the data items in question and
monitor them for subsequent changes. Thus the
systems administrator can think of the whole data
center as a form of dynamically changing database.
Were this the end of the story, Astrolabe might be
best understood as a new kind of network monitoring
system. However, the goal of the technology is to offer
a fundamentally new kind of operating systems service,

accessible not just to human administrators but also to
applications. Here, the point is that Astrolabe offers a
consistent, robust state representation that can be
exploited by the application itself. When an event
occurs that disrupts state – a machine crashes, or a
service hangs – the deviation from the nominal state
will become globally evident within seconds. Every
healthy program will simultaneously notice failures or
degradation.
Observing the problem, the many
programs that comprise the system can respond in a
coordinated manner. For example, some server might
take over tasks that a failed server had been responsible
for, and advertise its new role. Other servers, seeing
this, can establish new connections to the server in
question and interrogate it about work in progress.
In practice, we would not necessarily expect the
applications themselves to detect degradation in an
automated manner. Doing so presumes a degree of
automated intelligence that, for a complex application,
probably goes beyond what is reasonable. But humans
can fill in this component of the loop.
The
administrator, seeing a problem, she can flag servers in
the Astrolabe table by defining aggregation queries that
identify such servers, with a sufficient degree of built-in
delay to avoid a “flapping state” problem if a server
fails intermittently only to quickly recover. The
application program thus uses Astrolabe to sense
overall state but relies on a human-defined notion of
“degradation” to identify servers that are operational
but malfunctioning.
Now, suppose that we stand on the data center and
look out towards the client platforms. To what degree
can Astrolabe improve the experience of the end-user?
Above, we suggested the use of Astrolabe to monitor
the states of client systems. Merely by taking this step,
the data center gains a completely new kind of
functionality. Traditionally, we have viewed a data
center as being operational and “healthy” provided that
the servers seem to be working properly. Suddenly, the
option of focusing on the client’s experience of the
system becomes available. This type of information has
never before been available during periods of
disruption.
The mere knowledge that the servers are not aware
of problems tells us relatively little about the client
experience. A client connected to the closest, least
loaded server may still be experiencing disrupted
downloads and poor throughput because of network
problems such as overloads and router or link failures.
Yet, once we can sense such conditions, we can begin

to talk about responses such as redirecting that client to
some other server, perhaps one that is handling a
heavier load or seems to be more remote in the
network, and yet that is capable of offering a better enduser experience. A system can adapt even without
knowing why it is having problems.
Similarly, Astrolabe can offer the client system
better options for connecting to the server pool. To the
degree that we wish to expose such information, clients
can be shown information about which servers are
handling which categories of data, server load, average
service response times, availability of data replicas, and
so forth. These kinds of information can be used as
input to a client-side decision-making process
concerning the best server to handle a given kind of
request. The administrator controls the configuration
of Astrolabe and hence can easily select the data that
clients can see. Keep in mind that the clients we have
in mind are software – the 4th tier client-side
applications developed originally by the designers of
the data center. So we are not proposing that end-users
would “see” the state of the data center, but merely that
the software they downloaded to use the data center
might be smarter about its current state, just as it could
be smarter about their states. The human user simply
experiences better performance and higher availability,
because problems are now sensed more rapidly and
reaction is more automated.
Our scenario started with a hypothesized timeout.
With Astrolabe in use, the client and data center both
“see” the system state in a consistent manner. If a
server has crashed, they both share this information,
and the client can track the progress of the backup
server in taking over, bringing itself back into sync
with the state of the failed primary server, and
eventually coming back online. Parameter settings
advertised through Astrolabe become globally visible
and updates are seen rapidly. Thus, a wide range of
autonomic
adaptations
become
relatively
straightforward.
This paper has mentioned distributed denial of
service attacks several times. As we conclude this
section, consider briefly the challenges of responding to
such an event. Commercial data centers are bedeviled
by such problems; few, if any, have escaped unscathed.
However, few of these attacks target more than a small
number of servers: they succeed precisely because the
attacker is able to marshal the resources of large
numbers of machines to overwhelm a small number of
target systems. Using Astrolabe, both servers and

clients can sense localized disruptions, reallocating
work and redirecting clients away from the disabled
systems. Even if an attack has never been seen
previously, by having system administrators in the loop
– for example, in a position to redefine the data-mining
query used to identify “faulty” servers – the capability
now exists for dynamically responding to attacks purely
by recognizing their symptoms. The effect is that the
data center will seamlessly and automatically shift tasks
away from faulty servers and towards those not
currently under attack. The DDoS attacker will lack
the resources to attack all servers and thus will be
frustrated. As he discovers that his attack is having
little impact on performance, he is likely to abandon the
effort in favor of more promising targets.
Earlier we spoke of the many ways that autonomic
computing is viewed by potential developers and users.
Astrolabe can support even more ambitious styles of
computing, extending to the kinds of resource-location
problems that need to be solved to support selfaggregating computing platforms.
We see the
technology as opening the door to a major advance in
computing styles.
Astrolabe has been designed to interoperate
comfortably in a world of Web Services and data
centers. While the sorts of uses just summarized would
require a substantial integration effort between the
vendor of the Web Services platform and our
development team, there are no obvious obstacles to
undertaking such an effort.
Some of the Astrolabe uses outlined here require a
degree of caution on the part of the programmer.
Recall that consistency in Astrolabe is a probabilistic
property. Data will converge over time (so that, given
enough time – seconds or minutes – multiple viewers
will see the same data) but not instantly. Thus, some
caution must be taken in the way that Astrolabe is used.
Actions should be triggered only after a pause to give
the system time to stabilize, and applications should be
designed to watch for evidence of “flapping” systems or
other anomalies. However, if actions are based on
stable states and delayed by long enough to give
Astrolabe itself time to reach a quiescent state, the
approach offers a high degree of robustness and actions
taken will be coordinated with extremely high
probability. We are doubtful that any technology could
offer stronger guarantees.
To reiterate a point made previously, today, the
developer of a sophisticated distributed computing

system is asked to work in the dark. This limits
availability and makes such systems far more expensive
to administer than need be the case. With new services
such as the Astrolabe service, we can turn on the lights,
enabling a new generation of far more automated
computing systems that perform well under all sorts of
conditions, adapt as conditions change, and configure
themselves without requiring endless human
intervention.

6

Performance

The dual goals of keeping this paper brief and of
avoiding repetition of material reported elsewhere led
us to omit any detailed performance section from this
paper. However, Astrolabe is a real system and we
have evaluated it in great detail. The interested reader
is referred to [7]. The technology really works, and is
available from our group at Cornell.
Broadly, our evaluation consists of four parts. In a
first step, we used formal methods to develop a
theoretical analysis of the scalability and propagation
properties of the system. Such an analysis is interesting
to the extent that it seems to confirm our observations
of behavior, but also limited insofar as we are forced to
simplify the real world in order to reason about the
technology. The analysis predicts the logarithmic
scalability properties outlined earlier, and also lets us
predict the distribution of update delays. Our work
suggests that the exponential wave of infection that
propagates updates not only makes the protocol itself
robust to failures or network disruption, but also makes
our analysis robust to these simplifications. In effect,
when simplifying the model of a network, one perhaps
arrives at behavioral predictions that are overly
optimistic or pessimistic. But because that behavior is
so strongly dominated by the exponential spread of
information, such an error only leads to a minor
inaccuracy. Our experience has been that the formal
analysis of Astrolabe is highly predictive of its
behavior.
Without wanting to digress into theory, it is still
worthwhile to observe that we’ve been astonished at the
power of theory to predict Astrolabe’s behavior. This is
surprising because for decades, distributed computing
systems developers have had an uncomfortable
relationship with theoreticians working in their area.
There is a great deal of theory applicable to distributed
computing, yet one finds that much of this work is
simply not useful in practical settings – the models are
oversimplified, or result in inaccurate predictions, or
seem to yield unreasonably pessimistic conclusions.

With Astrolabe, none of these problems has arisen. We
attribute this to the exponential wave of information
flow at the core of Astrolabe. Even if the model of the
network used in our theoretical work is a bit simplistic,
the model probably covers “enough” of the behavior of
the network so that the theory can describe at least a
subset of what happens in the real setting. Perhaps the
resulting predictions are inaccurate in some small ways,
but these issues are dwarfed by the overwhelming
convergence properties of the protocols. We’ve been
very pleased by this finding, and are using theoretical
analysis of our protocols much more successfully than
in any of our own past work.
A second style of evaluation focuses on two kinds of
simulation. First, using network simulation systems (a
hand-built event simulator) we have simulated
Astrolabe to understand its behavior in a variety of
network topologies and under a variety of loads and
scales. Second, we have looked at the behavior of our
Astrolabe implementation by running the real software
over a simulated network. We do this by injecting
packet loss or delays so as to emulate conditions that
might be encountered in the field. Cornell is fortunate
in having a very powerful emulation platform, and this
makes it possible to explore large, complex scenarios
that are not suitable for simulation studies.
Finally, we have worked with Astrolabe in real
world settings, and evaluated its behavior as it runs.
While such an approach has the benefit of being an
evaluation of a real system in a real setting, one also
has less control over competing applications which
share resources, less ability to reproduce scenarios to
understand precisely how they gave rise to an observed
behavior, and less opportunity to systematically vary
parameters which determine behavior.
Jointly, these studies have confirmed that Astrolabe
indeed exhibits the predicted logarithmic growth in
update propagation latency, and that the system has
stable, low, computing and communication loads. We
have subjected Astrolabe to a variety of stresses
(failures, packet loss) and found it to be robust even
under rather severe attacks. In particular, conditions
similar to those seen during distributed denial of
service (ddos) attacks slow Astrolabe down, but not
very much, and do not trigger any substantial growth in
message rates or loads associated with the technology.
This suggests that Astrolabe may remain useful even
when a network is experiencing severe disruption. The
possibility of using Astrolabe for distributed detection

of such episodes and to trigger a coordinated response
appears to be very promising.

7

Related Work

Our work draws heavily on prior research in peer-topeer computing and databases. In the database area,
the idea of building replicated databases using gossip
communication dates to the Xerox Clearinghouse
server, a flexible directory service for large networks.
Discussion and analysis of the protocols used in this
system appears in [2]. Subsequent Xerox work on a
database system called Bayou takes the idea even
further [6], and also includes a formal analysis of the
scalability of push and pull gossip. The idea of
building large-scale information systems hierarchically
is an old one; many elements of our approach were
anticipated by Lampson [5] and Golding [3]. Work on
treating large sensor networks as databases can be
found in [1]. The Ninja system replicates data using a
peer-to-peer protocol similar to the one we use in
Astrolabe, but lacks an aggregation mechanism [4].

8

Conclusions

The Astrolabe system creates a new option for
developers of ambitious autonomic computing
applications that run in large networks. Our work
shows that such a technology can be extremely valuable
in transitioning from a traditional 3-tier Web
architecture to a 4-tier Web Services architecture with
greatly increased numbers of components. We believe
that our paper is the first to point to autonomic
opportunities on the client-side of such systems, which
have traditionally been left somewhat in the dark
during periods when servers are unreachable or giving
degraded response. Client-side interventions promise
greatly improved performance and reliability under
conditions in which more traditional architectures
might leave the client systems visibly degraded or
incapacitated without action by a human administrator.
Whereas traditional approaches collect data in a
centralized server, Astrolabe implements a novel peerto-peer protocol whereby queries can be computed
directly in the network by the participating computers
themselves.
Although the loads imposed on
participating computers are very small (and
independent of the size of the system), the aggregated
computing capability may be huge, hence we are able to
solve problems that would be infeasible in a centralized
solution. Moreover, the approach scales much better

than centralized ones, is robust against failures and
attack, and propagates updates within seconds or tens
of seconds even in networks with huge numbers of
computing nodes.

Acknowledgements
Our group is grateful to Dr. Tushar Chandra and Dr.
Alan Ganek or IBM, who brought us into dialog with
the Autonomic Computing community, and to our
colleagues in the Air Force Research Laboratory
Information Assurance Institute, at IBM Research, and
at Amazon.com for their help in understanding some of
the challenges arising in systems architected using the
current generation of Web Services technologies.

References
[1] P. Bonnet, J.E. Gehrke, P. Seshadri. Towards
Sensor Database Systems. In Proc of the 2nd Intl. Conf.
On Mobile Data Management. Hong Kong, Jan. 2001.
[2] A. Demers, D. Greene, C. Hauser, W. Irish, J.
Larson, S. Shenker, H. Sturgis, D. Swinehart and D.
Terry. Epidemic Algorithms for Replicated Database
Management. In Proc. of the 6th ACM Symposium on
Principles of Distributed Computing, 1-12, Vancouver
BC, Aug. 1987.
[3] R.A. Golding. A Weak-Consistency Architecture
for Distributed Information Services.
Computing
Systems, 5(4):379-405, Fall 1992.
[4] S.D. Gribble, M. Welsh, J.R. von Behren, E.A.
Brewer, D.E. Culler, N. Borisov, S.E. Czerwinski, R.
Gummadi, J.R. Hill, A.D. Joseph, R.H. Katz, Z.M.
Mao, S. Ross, B.Y. Zhao. The Ninja Architecture for
Robust Internet-Scale Systems and Services. Special
issue of Computer Networks on the topic of Pervasive
Computing. 35(4):473-497, 2001.
[5] B.W. Lampson. Designing a Global Name
Service. In Proc. of the 5th ACM Symposium on
Principles of Distributed Computing.
Calgary,
Alberta, Aug. 1986.
[6] K. Petersen, M.J. Spreitzer, D.B. Terry, M.M.
Theimer, and A.J. Demers.
Flexible Update
Propogation for Weakly Consistent Replication. In
Proc. of the 16th ACM Symposium on Operating
Systems Principles, 288-301, Saint-Malo, France, Oct.
1997.

[7] R. van Renesse, K.P. Birman, and W. Vogels.
Astrolabe: A Robust and Scalable Technology for
Distributed System Monitoring, Management and Data
Mining. ACM Trans. on Computer Systems, 21(3),
May 2003. http://www.cs.cornell.edu/ken/Astrolabe.pdf

